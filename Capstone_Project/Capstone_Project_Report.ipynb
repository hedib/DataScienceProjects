{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/latex"
   },
   "source": [
    "#  Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "latex_metadata": {
     "affiliation": "Freie Universit\\\"at Berlin, Fachbereich Physik, 14195 Berlin, Germany",
     "author": "Julius C. F. Schulz",
     "title": "Amazing Article"
    },
    "raw_mimetype": "text/latex"
   },
   "source": [
    "## Description of the Problem  \n",
    "\n",
    "Product backorders is a typical supply chain problem. Backordering happens when a customer places an order for a product that is temporarily out of stock with the vendor and order cannot be fulfilled.\n",
    "It is a dream for any business, but it is also a massive problem if we do not know how to handle it.\n",
    "<br>\n",
    "In this project, the goal is to identify the cause of backorder and use the past data around the backorders to develop a model to predict the probability of a product backorder.\n",
    "With the help of data analysis, a reasonable prediction on all products can go on backorders is expected. Such a prediction\n",
    "could immensely help the client to plan for a more efficient stocking and backorder handling.\n",
    "Goals of this project are:  \n",
    "\n",
    "- Provide an overall insight from data using exploratory data analysis. \n",
    "\n",
    "- Identifying what the main features are caused backorders the most?  \n",
    "\n",
    "- Predict the probability of a product backorder.    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preview of Data Analysis\n",
    "\n",
    "The client is looking for ways to improve backorders handling. With the help of data analysis, a reasonable prediction on the products that can go on backorder is expected. Such a prediction could immensely help the client to plan for a more efficient stocking and backorder handling.\n",
    "Using the dataset, I want to answer to main questions:  \n",
    "\n",
    "1. How common is backorder?\n",
    "\n",
    "2. What is the relationship of features with backorders?  \n",
    "\n",
    "3. Based on backorder risks what would be biggest risks?  \n",
    "\n",
    "\n",
    "Answers to these questions will enable me to identify the main causes of backorders and predict the probability of backorders.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, I used the dataset available on the Kaggle website. The training data file contains the historical data for the eight weeks before the week we are trying to predict product backorders. The data took as weekly snapshots at the start of each week.\n",
    "\n",
    "Dataset was acquired from https://www.kaggle.com/tiredgeek/predict-bo-trial. Dataset composed of one file named \"Training_Dataset.\"The training file was opened and stored in a data frame using python.\n",
    "The dataset contains the historical data, and it has 23 columns and 1687860 entries, and entirely has 100894 missing data also some entries of two columns include -99 values.The missing data is an example of Missing at Random data mechanism where missing data is related to observed data.\n",
    "\n",
    "Dataset columns are defined in Table 1:  \n",
    "\n",
    "![Table 1. Dataset columns](img/table.png)\n",
    "\n",
    "Data wrangling goals: Prepare the backorder dataset for EDA and Modeling  \n",
    "\n",
    "Tasks performed:  \n",
    "\n",
    "- Handling missing Data  \n",
    "\n",
    "- Convert to binary  \n",
    "\n",
    "- Handling the outliers  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to binary\n",
    "\n",
    "In this dataset, every categorical feature includes only two values: 'Yes' and 'No' for reducing memory usage binaries converted from strings ('Yes' and 'No') to 1 and 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Data\n",
    "\n",
    "In this part I try to find which columns in the dataset contain missing values and drop or replace those missing values so I’ll have tidy data. \n",
    "All columns in dataset footer had missing values and represented as NaN, so I dropped that row.\n",
    "Columns \"perf_12_month_avg\" and \"perf_6_month_avg\" have missing value as -99.There is a strong correlation between \"perf_6_month_avg\" and \"perf_12_month_avg\". So, linear regression would use to\n",
    "filing missing values. However another interesting point to note here is that many observations have both \"perf_12_month_avg\" and \"perf_6_month_avg\" as null, so linear regression cannot fill such values, and we need to see \n",
    "another approach there. Probably we would like to check for the central tendency of the data and replace the null accordingly. \n",
    "<br>\n",
    "It is visible from the seaborne plot(Figure 1) that data was not distribute normally. Therefore picking median to fill remaining values is a good choice.  \n",
    "\n",
    "![Figure 1. Source performance for prior six vs. twelve months](img/perf.png)  \n",
    "\n",
    "\"Lead_time\" column had 100893 missing values, and it was not clear if it was missing or not. It is quite likely that when \"lead \n",
    "time\" is missing, it is missing for a reason and not at random, which means a mean/median imputation strategy may not be \n",
    "appropriate. I preferred to decide by looking at data with calculating the proportion of backordered products vs. without a \n",
    "missing value in \"lead time.\"  \n",
    "\n",
    "The calculation below shows how to handle missing data in \"lead time\":  \n",
    "\n",
    "1.Proportion of orders that “went_on_backorder” for missing \"lead_time\" records.  \n",
    "\n",
    "2.Proportion of orders that “went_on_backorder” for non-null \"lead_time\" records.  \n",
    "\n",
    "Went on backorder percentage for all orders that they \"went on backorder\" is 0.66%.  \n",
    "\n",
    "![Figure 2. Went on backorder percentage](img/pie.png)\n",
    "\n",
    "Based on the above proportion calculations the proportion of backordered products with missing \"lead time\" is 50% less than those without\n",
    "missing \"lead time.\" The proportion of backordered products with missing \"lead time\" is half of the products with no missing values.\n",
    "The amount is significant enough that I decided not to replace the missing data in \"lead time\" and drop them.  \n",
    "\n",
    "![Figure 3. Lead time vs. went on backorder](img/lead.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling the outliers  \n",
    "\n",
    "The Next step is looking at the relationship between \"lead time\" and a fraction of products that went on backorder. Let's look at the \"lead time\" and how it changes the probability of went to backorder. Products that \"went on backorder\" with \"lead\n",
    "time\" eight weeks and then two weeks have the highest order volumes. The plot below shows the relation between \"lead time\" and the fraction of backorder.  \n",
    "\n",
    "The Figure 4 plot shows with longer \"lead time\" backorder proportion goes down. In the following Figure, two outliers noticed. One is at \"lead time\"=11 and one at \"lead time\" 52. For the point on 52, I believe there were not enough records to show the rest of point between 17 to 52. The point at \"lead time\" 11 should be given particular attention to its cause is known. For this reason, I am going to calculate the binomial probability distribution. As you see from the above calculations, the standard deviation of the binomial distribution is 3.23 standard deviation from the mean, so I am going to ignore this point for now.  \n",
    "\n",
    "![Figure 4. Lead time ratio](img/ratio.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explorotary Data Analysis  \n",
    "\n",
    "A list of questions about the data set were answered. There are 8 questions answered that aims to help achieve the goals of this project.\n",
    "\n",
    "1. How common are backorders? \n",
    "\n",
    "2. Given that, how likeliest are \"backorders\" based on the \"part risk flags”? And how prevalent are they? \n",
    "\n",
    "3. What’s the relationship between product sales and forecast? \n",
    "\n",
    "4. What's the relationship between \"part risk flags\" or are that unrelated concepts? \n",
    "\n",
    "5. What's the relationship between \"lead time\" and \"went on backorders\"?  \n",
    "\n",
    "6. What aspects of supply chain represent the biggest risks?  \n",
    "\n",
    "7. Based on backorder risks what would be recommended improving first?   \n",
    "\n",
    "## Relationship between total sales and total sales forecast\n",
    "\n",
    "Figure 5 shows the strong relationship between total prior sales and total prior sales forecast. Product backorder can Happen because of the wrong forecast. For example, when for any reason sales forecast is less than actual sales of the month.\n",
    "In this data set from 11293 backordered products, 4274 orders sales were more than sales forecast, so more than half of the backordered products happened because of the other reasons.\n",
    "\n",
    "![Figure 5. Total sales vs. Total forecast](img/forc.png)  \n",
    "\n",
    "## Relationship between \"lead time\" and \"went on backorders\"\n",
    "\n",
    "Figure 6 shows that \"lead time\" of backordered orders looks exactly like the plot of lead time with not backorder data. It means\n",
    "that most of the products not \"went on backorder\" and if we choose the random sample of data, it is the same distribution.\n",
    "Therefore we are going to see if \"lead time\" and \"went on backorder\" are dependent or independent to/from each other.\n",
    "Products that went on bacorder with lead time 8 weeks and then 2 weeks have the highest order volumes.  \n",
    "\n",
    "![Figure 6. Lead time vs. went on backorder](img/weeklead.png)  \n",
    "\n",
    "## \"Total Sales\" relationship with  \"Went on backorder\"\n",
    "Figure 7 shows with higher sales percentage of sales that went on backorder increased.\n",
    "\n",
    "![Figure 7. Total sales percentage that went on backorder](img/salesratio.png)  \n",
    "\n",
    "## Relationship between categorical columns and \"went on backorder\"\n",
    "\n",
    "The categorical columns in the dataset are:  \n",
    "\n",
    " -  \"potential_issue\" - Source issue for part identified  \n",
    " \n",
    " -  \"pieces_past_due\" - Parts overdue from source  \n",
    " \n",
    " -  \"local_bo_qty\" - Amount of stock orders overdue  \n",
    " \n",
    " -  \"deck_risk\" - Part risk flag  \n",
    " \n",
    " -  \"oe_constraint\" - Part risk flag  \n",
    " \n",
    " -  \"ppap_risk\" - Part risk flag  \n",
    " \n",
    " -  \"rev_stop\" - Part risk flag\n",
    " \n",
    " -  \"stop_auto_by\" - Part risk flag\n",
    " \n",
    "The Figure below shows that \"lead_time\" has the same relationship with \"went on backorder\" and \"potential issues.\" It means when products with specific \"lead time\" did not have the \"potential issue,\" the products did not go on backorder as well.  \n",
    "\n",
    "![Figure 8. potential issue vs backorder](img/pot.png)  \n",
    "\n",
    "Same thing with parts overdue; there are no parts overdue from the source the products do not go backorder.The probability \n",
    "of products without any of risk that did not go on backorder is almost 98%. If the product did not have parts overdue, it is \n",
    "doubtful it went on backorder.On the other hand The probability of product had any of risks and \"went on backorder\" is very \n",
    "low but the intersting part is probability of product had \"pieces past due\",\"local_bo_qty\",\"potential_issue\" and \"went on backorder\" is 96%. It means the combination of these flags affects the going on backorder.\n",
    "\n",
    "I used crosstabulation and chi-square to find the relation between target variable with other categorical variables.\n",
    "Below are the calculated values.(Table 2)  \n",
    "\n",
    "![Table 2. chi square and p-value of categorical features](img/chi.png)  \n",
    "\n",
    "All the relations have p-values less than 0.05 and we also have chi-square calculated value greater than the chi-square critical value. Based on these two evidences, I rejected the null hypothesis that variables are independent and went ahead with the alternate hypothesis.\n",
    "Here we can say that went_on_backorder is related to \"potential_issue\",\"pieces_past_due\" , \"local_bo_qty\" ,\"deck_risk\" ,\"oe_constraint\",\"ppap_risk\",\"rev_stop\" and \"stop_auto_buy\", so I will keep all these features for modeling.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Minimum recommended amount of stock\" and \"went on backorder\"\n",
    "\n",
    "With more \"minimum recommended amount of stock\" the order volumes decrease.The proportion of orders with the minimum recommended \n",
    "an amount to stock that \"went_on_backorder\": 0.66%. \n",
    "Another observation around the recommended stock where we can see that total perior sales were zero, however, the minimum recommended stock is kept at a high value. This could be a bad data or potential outliers(Figure 9).\n",
    "\n",
    "![Figure 9. minimum recommanded amount of stock vs went on backordere](img/min.png)  \n",
    "\n",
    "![Figure 10. minimum recommanded amount of stock vs prior total sales](img/minratio.PNG)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data reduction\n",
    "\n",
    "Since the dataset was massive, I decided to reduce data by capturing data from the total sales volume which is a significant\n",
    "reduction in data for not much loss of fidelity.  \n",
    "\n",
    "How I captured the total sales values is I used the cumulative sum of total sales volume.For data reduction, I captured 60% \n",
    "total sales volume, which is data was reduced to 7397 rows.  \n",
    "\n",
    "Using data reduction may save some computing time and also presenting a cleaner dataset for the predictive model.<br>\n",
    "Backorder percentage is higher when we drop the NaN values in \"lead time\" that's because most of the orders were not backordered.\n",
    "There were no significant differences in the result of data reduction when I dropped missing values of \"lead time\". In my opinion, \n",
    "missing values in lead time do not affect the result of volume reductions.\n",
    "\n",
    "Therefore other reasons might affect backorders.  \n",
    "\n",
    "In the following exploratory I answer these questions:  \n",
    "\n",
    "-  Given that, how likely are backorders based on the \"part risk flags\"?  \n",
    "\n",
    "-  How prevalent are they?  \n",
    "\n",
    "-  What is the relationship between \"potential_issue\" and \"pieces_past_due\" are each  \n",
    "\n",
    "-  What is the relationship between \"potential_issue\" and \"pieces_past_due\" are each represented by part risk flags or are \n",
    "they unrelated concepts?  \n",
    "\n",
    "-  Based on the answers to these questions you could recommend: What aspects of the supply chain present the most prominent \n",
    "risks?  \n",
    "\n",
    "-  Based on the risks, what would be recommended improving first?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization\n",
    "\n",
    "The attributes related to quantities were normalized (std dev equal to 1) per row. Therefore, parts with different order of magnitudes are approximated. For example: 1 unit of a expensive machine may be different from 1 unit of a screw, but if we standard deviate all the quantities we have, we can get a better proportion of equivalence between those items.\n",
    "The Figure 9 shows sales column's distributions after normlization.  \n",
    "\n",
    "![Figure 11. Normalization histogram](img/norm.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imbalanced classification is a supervised learning problem where one class outnumbers other class by a large proportion.This \n",
    "problem is faced more frequently in binary classification problems than multi-level classification problems.The reasons which \n",
    "leads to reduction in accuracy of ML algorithms on imbalanced data sets:  \n",
    "\n",
    "- ML algorithms struggle with accuracy because of the unequal distribution in dependent variable.  \n",
    "\n",
    "- This causes the performance of existing classifiers to get biased towards majority class.  \n",
    "\n",
    "- The algorithms are accuracy driven i.e. they aim to minimize the overall error to which the minority class contributes very \n",
    "little.  \n",
    "\n",
    "- ML algorithms assume that the data set has balanced class distributions.  \n",
    "\n",
    "- They also assume that errors obtained from different classes have same cost.  \n",
    "\n",
    "Because the data set is very imbalanced so I add up the data that went on backorder to this sample.\n",
    "\n",
    "In this data set target value is \"went_on_backorder\".\n",
    "\n",
    "The features that I used to train the machine learning model are presented in the list below:  \n",
    "\n",
    "![Model Features](img/features.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model selection  \n",
    "\n",
    "The training data set the amount of backoredered products are less than 1% of the whole products,so the data is very imbalanced.\n",
    "Therefore I add up the data that \"went on backorder\" to this sample.\n",
    "I used supervised learning to predict “went on backorder” product according to what they have reordered. \n",
    "Result shows the accuracy of 99%.  \n",
    "\n",
    "Data trained in two supervised models logistic regression, and random forest(Bagging-based ensemble).Comparing these two models in logestic regression model first because data was imbalance it showed high accuracy.\n",
    "That reason is, Logistic regression produces an estimated probability that a particular instance is from the positive class. It caused the classifier to over-predict positive instances. For some classifiers, it is not a significant problem, but I expect that logistic regression might be more sensitive to this mismatch between training distribution and test distribution.  \n",
    "\n",
    "After balancing the data set, I used regularization with my logistic regression model and used cross-validation to select the regularization hyper-paramete to find a suitable threshold that maximizes the F1 score (or some other metric).  \n",
    "\n",
    "A logistic regression model is searching for a single linear decision boundary in the feature space, whereas a decision tree is essentially partitioning the feature space into half-spaces using axis-aligned linear decision boundaries. The net effect is that it is a non-linear decision boundary, possibly more than one.\n",
    "This is nice when a single hyperplane does not readily separate the\n",
    "data points, but on the other hand, decisions trees are so flexible that they can be prone to overfitting. To combat this, I used the random forest. Logistic regression tends to be less susceptible (but not immune!) to overfitting.  \n",
    "\n",
    "I used ROC AUC score since it gives the probability of an estimator ranking a positive example higher than a negative example.\n",
    "This way it can evaluate the models before selecting a threshold for the decision function. \n",
    "Also I looked at ‘Precision’ as validation criteria because it is important that as many of the records predicted are correct as possible so that time is not wasted working on false positives.  \n",
    "![Table 3. logestic regression precision and recall score](img/logestic.png)  \n",
    "\n",
    "\n",
    "RandomForestClassifier had good Precession score compare to all other classifiers.Model Validation: Model is trained on 80% of the data and and 32% is the test data below is the precision score on 10 folds.The features importance in random forest model  are: sales_3_month and lead_time.  \n",
    "\n",
    "\n",
    "![Table 4. Random Forest precision and recall score](img/rf.png)  \n",
    "\n",
    "\n",
    "![Figure 12. Predictable vs actual label](img/predict.png)  \n",
    "\n",
    "Precision-recall curves show how Precision and Recall metrics compete depending on the threshold defined for the decision function of the model.  \n",
    "\n",
    "Following is the ROC curve for the case in hand.  \n",
    "\n",
    "![Figure 13. ROC curve](img/auc.png)  \n",
    "\n",
    "![Figure 14. recall precision curve](img/recal.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knowing the cause of backordering help company's inventory management to plan for a more efficient stocking and backorder handling. A company can manage its inventory more efficiently using a prediction on the backorder risk for the products.In this project, the goal was using the past data and metadata around the product backorders, and provide a prediction of the potential products for backorders.\n",
    "\n",
    "Data analysis showed that lead time has a relationship with product backorders, longer lead time, backorder proportion goes down. Also, sales have a strong relationship with back orders. \n",
    "\n",
    "All other categorical variables have relationships with backorders, but some of them have more. For example probability of a product that went on backorders and had three risk flags: parts overdue, potential issue, and local stock overdue is 97%.\n",
    "All the categorical variables relation with backorder have p-values less than 0.05. Also chi-square calculated values are higher than the chi-square critical value. Based on these two pieces of evidence, the null hypothesis was rejected that variables are independent and went ahead with the alternate hypothesis.  \n",
    "\n",
    "I used supervised learning to predict product backorders accurately. Dataset is highly imbalanced. We have only 0.66% data as ‘Yes’ to back order, so accuracy cannot be validation criteria here. Because of imbalanced data, I added more \"yes\" to backorder data to the dataset.I used ‘AUC’ score and ‘Precision’ as validation criteria.\n",
    "\n",
    "After calculating AUC and precision-recall scores, RandomForestClassifier has better AUC and precision value. I decided to tune and validate these models.For tuning the parameters of the model, I used a mix of cross-validation and randomized search.\n",
    "\n",
    "Based on the performances of the predictive models,  I found tuned RandomForestClassifier as the most suitable predictive model to choose in this project. I recommend this model to the client as it has Auc 99% and a precision score of 1.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All solutions can be viewed in IPython Notebook in my github below.  \n",
    "\n",
    "https://github.com/hedib/DataScienceProjects/blob/master/project_Inventory/backorder.ipynb"
   ]
  }
 ],
 "metadata": {
  "CodeCell": {
   "cm_config": {
    "lineWrapping": false
   }
  },
  "MarkdownCell": {
   "cm_config": {
    "lineWrapping": false
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "latex_metadata": {
   "affiliation": "Freie Universit\\\"at Berlin, Fachbereich Physik, 14195 Berlin, Germany",
   "author": "Julius C. F. Schulz",
   "title": "Amazing Article"
  },
  "metadata": {
   "collapsed": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
